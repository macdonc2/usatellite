{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am making this package to practice my OOP skills using Python.  It is based on the work of Michael Morphew, whos Github account is here:\n",
    "\n",
    "https://github.com/mmorphew\n",
    "\n",
    "We are interested exploring the use of UNet (https://arxiv.org/abs/1505.04597), which is perhaps the most commonly used Deep Learning neural network architecture for semantic segmentation, for pixelwise classification of satellite images.  We hope to create a concise package for this specific task and set up a dashboard for users to experiment.  I hope to learn Plotly Dash for this activity, but we will see where we end up.  Along the way, I would also like to optimizie some hyperparameters of the model using some open-source packages and provide some simple explainations for non-ML and/or optimization experts.\n",
    "\n",
    "Michael has obtained the data from..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Importing my first modules from my first package\n",
    "\n",
    "from data_utils.dataset import DataLoader         #  From usatellite\n",
    "from preprocessing.preprocessor import TopHatFilter     #  From usatellite\n",
    "\n",
    "#  Import list\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt # for QC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get into the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we will create a data_loader object from the Dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The load_list method isn't actually loading the data, it is just setting up the paths to files on disk.  Under the\n",
    "hood, we use tifffile to import the tiff files.  If you have images of another format, such as .png or.jpg, \n",
    "please feel free to investigate other packages.  It is typically straight forward to load images using Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = loader.load_list('ISPRS/top', 'top_mosaic_09cm_area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check out imgs, we will see that the sorting of file names is not great...  Later, this will be an issue, because the dsm data is brought in with an incompatible sorting.  The labels for objects of interest are likely out of sync as well.  \n",
    "\n",
    "Darn!  \n",
    "\n",
    "Let's use a built in method to fix this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = sorted(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not crazy about the naming conventions for this dataset, but I'm also lazy.  This should at least work for our purposes, but please note that sorted does not seem to be an in place operation, so we need to re-assign the imgs.\n",
    "\n",
    "Let's use list comphrehension to check out the list of images in imgs after sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISPRS/top/top_mosaic_09cm_area1.tif\n",
      "ISPRS/top/top_mosaic_09cm_area10.tif\n",
      "ISPRS/top/top_mosaic_09cm_area11.tif\n",
      "ISPRS/top/top_mosaic_09cm_area12.tif\n",
      "ISPRS/top/top_mosaic_09cm_area13.tif\n",
      "ISPRS/top/top_mosaic_09cm_area14.tif\n",
      "ISPRS/top/top_mosaic_09cm_area15.tif\n",
      "ISPRS/top/top_mosaic_09cm_area16.tif\n",
      "ISPRS/top/top_mosaic_09cm_area17.tif\n",
      "ISPRS/top/top_mosaic_09cm_area2.tif\n",
      "ISPRS/top/top_mosaic_09cm_area20.tif\n",
      "ISPRS/top/top_mosaic_09cm_area21.tif\n",
      "ISPRS/top/top_mosaic_09cm_area22.tif\n",
      "ISPRS/top/top_mosaic_09cm_area23.tif\n",
      "ISPRS/top/top_mosaic_09cm_area24.tif\n",
      "ISPRS/top/top_mosaic_09cm_area26.tif\n",
      "ISPRS/top/top_mosaic_09cm_area27.tif\n",
      "ISPRS/top/top_mosaic_09cm_area28.tif\n",
      "ISPRS/top/top_mosaic_09cm_area29.tif\n",
      "ISPRS/top/top_mosaic_09cm_area3.tif\n",
      "ISPRS/top/top_mosaic_09cm_area30.tif\n",
      "ISPRS/top/top_mosaic_09cm_area31.tif\n",
      "ISPRS/top/top_mosaic_09cm_area32.tif\n",
      "ISPRS/top/top_mosaic_09cm_area33.tif\n",
      "ISPRS/top/top_mosaic_09cm_area34.tif\n",
      "ISPRS/top/top_mosaic_09cm_area35.tif\n",
      "ISPRS/top/top_mosaic_09cm_area37.tif\n",
      "ISPRS/top/top_mosaic_09cm_area38.tif\n",
      "ISPRS/top/top_mosaic_09cm_area4.tif\n",
      "ISPRS/top/top_mosaic_09cm_area5.tif\n",
      "ISPRS/top/top_mosaic_09cm_area6.tif\n",
      "ISPRS/top/top_mosaic_09cm_area7.tif\n",
      "ISPRS/top/top_mosaic_09cm_area8.tif\n"
     ]
    }
   ],
   "source": [
    "for x in imgs:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#. Need to figure this out\n",
    "\n",
    "imgs_array = loader.load_and_resize_images(imgs, 512, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to have loaded the images to an array.  Let me explain this array for new comers...\n",
    "\n",
    "The array stores a set dimensionality of data.  The first dimension describes how many images we have.  The second and third dimsions are the width and height.  For simplicity, we have set these dimensions to be equal.  The final dimension holds \"channels\".\n",
    "\n",
    "I'm a geoscientist, so let me clarify this...  The definition of channel is not related to a sedimentary depositional feature, nor does it relate to earth systems!  Sorry rock jocks!  Channels simply help describe aspects of the array. In this case, channels are rgb descriptions of image color.  I prefer the rgb channels to populate the last index of an array, and I think this is the most common standard.  The first descriptor, index 0, is also considered a channel...  That is, the input channel for a machinelearning algorithm that looks at a number of examples of images.  \n",
    "\n",
    "Let's have a look at an example below.  User is specifying just the first entry with: imgs_array[0].  This is a short-hand means of using: imgs[0:,512,512;,3].  By default, Python will interpret this to mean that all the unspecified dimensions are their max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs_array[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah - looks like an aerial photograph.  I'm not used to this amount of red trees, though, so I have something to look into.  It may not really matter for our task, but it will confuse and distract clients of the tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK - we loaded satellite images, but you know what?  We have other data!  Let's use load_list to tier up another set of data - digital surface (elevation) maps.  We need to apply slightly different logic to add the listed files to an array, since it has only 1 channel description.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_list = loader.load_list('ISPRS/dsm', 'dsm_09cm_matching_area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_list = sorted(dsm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_array = loader.load_and_resize_dsm(dsm_list, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dsm_array[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domain knowledge can be pretty useful.  Michael informed me that dsm information is important in classifying\n",
    "things in satellite images.  You can probably see why in the image above...  Buildings are tall and roads are not...\n",
    "At least, relatively speaking.  We probably want a classifier to be invariant to overall gradient/\n",
    "topography.  Luckily, this is not Michael's first rodeo with this kind of problem, and he has suggested on means of \n",
    "adjusting via a top hat filter.  Let's apply the filter (with a kernel size I dialied in for now) to have a look.\n",
    "\n",
    "### ML NOTE\n",
    "\n",
    "By the way, what proceeds is feature engineering.  That is, we are deterministically engineering features that will \n",
    "help statistical algorithms classify pixels in images.  Convolutional neural networks, given enough relevant images\n",
    "should be able to engineer features on their own - that is one of the big innovations with them. In my experience, they often engineer features that are more relevant than what we provide, so I typically avoid this.  However, we have few examples, so it will depend on our data augmentation tactics.  We can evaluate via metrics later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hat_filter = TopHatFilter(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_tophat = top_hat_filter.apply(dsm_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dsm_tophat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that bad if I say so myself.  These images are pretty simple compared to what we'd expect in the wild, but it is\n",
    "still encouraging that these open-source tricks can get us this far.  You should consider, though, that the image extraction itself relies on a kernel size.  What about when we want to perform inference?  Are we striding over larger images, or collection patchs for predictions?  There are a number of potential solutions, but we do not address that here.  \n",
    "\n",
    "In our case, images are of different size and we resize them to something common (512x512).  What the heck does this imply, though?  It's basically changing the true aspect ratio of the images!  Mind if someone squishes your neighborhood?  That's basically what we did.  It may not be an issue for the neural network.  In fact, this could be a nice data augmentation to help generalization...  But you, as a developer, should consider the implications and work with them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok - with that out of the way...  Let's visualize an image with the corresponding dsm (with inferno because I like the colormap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.randint(0,len(imgs_array))\n",
    "\n",
    "plt.imshow(imgs_array[ind], cmap='gray')\n",
    "plt.imshow(dsm_tophat[ind], cmap='inferno', alpha=0.5)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, ok.  Looks pretty decent on the data side.  It's even sorted consistently!  Let's see what we have for labels; note that there's a bit of logic under the hood that turns the rgb image into onehot encoded images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = loader.load_list('ISPRS/gt', 'top_mosaic_09cm_area')\n",
    "labels = sorted(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = loader.load_and_resize_rgb_labels(labels, 512, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.randint(0,len(imgs_array))\n",
    "\n",
    "plt.imshow(imgs_array[ind])\n",
    "plt.imshow(label_array[ind,:,:,1], alpha=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
