{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook, we will train a convolutional neural network to segment our satellite images.  We will first use our raw images, and then compare with extra features from previous engineering, such as as dsm with tophat filtering and nvdi.  Once as benchmark is set, we will look into hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preprocessing.preprocessor import Preprocess     #  From usatellite\n",
    "from models.unet2d.unet2d_model import Unet2d\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from loss.loss_metrics import Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we will load our data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = np.load('/Users/cody/Python/usattelite_data/img_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_array = np.load('/Users/cody/Python/usattelite_data/dsm_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvdi_array = np.load('/Users/cody/Python/usattelite_data/veggies_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = np.load('/Users/cody/Python/usattelite_data/label_array.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just start with our images as input to the network to provide a benchmark...  Later we will create more complex data structures, which contain more than just rgb.  These data will add the dsm and/or nvdi images as extra channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scale our data, since that is typically helpful for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array_scaled = preproc.unit_normalize_dims(imgs_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm actually going to just use sklearn's train test split to split up the data into traing and test data - there's really no reason to write our own code for this.  We will also shuffle the data and set a random state so it's reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(imgs_array, label_array, test_size=0.30, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet2dmodel = Unet2d(input_img=imgs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet2dmodel_obj = unet2dmodel.get_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet2dmodel_obj.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[\"categorical_accuracy\", Loss.f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.4510 - categorical_accuracy: 0.5178 - f1: 0.4501\n",
      "Epoch 00001: val_loss improved from inf to 9.61993, saving model to model-test-5.h5\n",
      "23/23 [==============================] - 180s 8s/step - loss: 1.4510 - categorical_accuracy: 0.5178 - f1: 0.4501 - val_loss: 9.6199 - val_categorical_accuracy: 0.2750 - val_f1: 0.1938\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.2252 - categorical_accuracy: 0.6603 - f1: 0.5341\n",
      "Epoch 00002: val_loss did not improve from 9.61993\n",
      "23/23 [==============================] - 170s 7s/step - loss: 1.2252 - categorical_accuracy: 0.6603 - f1: 0.5341 - val_loss: 11.7379 - val_categorical_accuracy: 0.2616 - val_f1: 0.1741\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.0998 - categorical_accuracy: 0.6982 - f1: 0.5974\n",
      "Epoch 00003: val_loss improved from 9.61993 to 8.71826, saving model to model-test-5.h5\n",
      "23/23 [==============================] - 177s 8s/step - loss: 1.0998 - categorical_accuracy: 0.6982 - f1: 0.5974 - val_loss: 8.7183 - val_categorical_accuracy: 0.2646 - val_f1: 0.2241\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.9946 - categorical_accuracy: 0.7199 - f1: 0.6425\n",
      "Epoch 00004: val_loss did not improve from 8.71826\n",
      "23/23 [==============================] - 175s 8s/step - loss: 0.9946 - categorical_accuracy: 0.7199 - f1: 0.6425 - val_loss: 11.3026 - val_categorical_accuracy: 0.2630 - val_f1: 0.2173\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.9242 - categorical_accuracy: 0.7227 - f1: 0.6710\n",
      "Epoch 00005: val_loss did not improve from 8.71826\n",
      "23/23 [==============================] - 169s 7s/step - loss: 0.9242 - categorical_accuracy: 0.7227 - f1: 0.6710 - val_loss: 10.5746 - val_categorical_accuracy: 0.2709 - val_f1: 0.2290\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8617 - categorical_accuracy: 0.7402 - f1: 0.6955\n",
      "Epoch 00006: val_loss improved from 8.71826 to 6.60285, saving model to model-test-5.h5\n",
      "23/23 [==============================] - 169s 7s/step - loss: 0.8617 - categorical_accuracy: 0.7402 - f1: 0.6955 - val_loss: 6.6028 - val_categorical_accuracy: 0.3148 - val_f1: 0.2884\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.7897 - categorical_accuracy: 0.7584 - f1: 0.7223\n",
      "Epoch 00007: val_loss improved from 6.60285 to 5.06435, saving model to model-test-5.h5\n",
      "23/23 [==============================] - 172s 7s/step - loss: 0.7897 - categorical_accuracy: 0.7584 - f1: 0.7223 - val_loss: 5.0643 - val_categorical_accuracy: 0.3611 - val_f1: 0.3742\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.7290 - categorical_accuracy: 0.7673 - f1: 0.7485\n",
      "Epoch 00008: val_loss improved from 5.06435 to 1.93801, saving model to model-test-5.h5\n",
      "23/23 [==============================] - 175s 8s/step - loss: 0.7290 - categorical_accuracy: 0.7673 - f1: 0.7485 - val_loss: 1.9380 - val_categorical_accuracy: 0.6247 - val_f1: 0.6254\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6764 - categorical_accuracy: 0.7782 - f1: 0.7642\n",
      "Epoch 00009: val_loss did not improve from 1.93801\n",
      "23/23 [==============================] - 171s 7s/step - loss: 0.6764 - categorical_accuracy: 0.7782 - f1: 0.7642 - val_loss: 4.3507 - val_categorical_accuracy: 0.4660 - val_f1: 0.4765\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6372 - categorical_accuracy: 0.7873 - f1: 0.7765\n",
      "Epoch 00010: val_loss improved from 1.93801 to 1.26761, saving model to model-test-5.h5\n",
      "23/23 [==============================] - 174s 8s/step - loss: 0.6372 - categorical_accuracy: 0.7873 - f1: 0.7765 - val_loss: 1.2676 - val_categorical_accuracy: 0.6809 - val_f1: 0.6834\n",
      "Epoch 11/100\n"
     ]
    }
   ],
   "source": [
    "results = unet2dmodel_obj.fit(x_train, y_train, batch_size=1, epochs=100, callbacks=unet2dmodel.callback_list(),\n",
    "                   validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
